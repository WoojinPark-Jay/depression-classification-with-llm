{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJYiV7fimi53",
    "outputId": "0ad1bfa4-4ca9-4e88-ae09-fe704df7988a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTj1HazlCpBq",
    "outputId": "0f59d770-57aa-4e58-c535-00045a950643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/2024_Unstructured_Data\n"
     ]
    }
   ],
   "source": [
    "%cd drive/MyDrive/2024_Unstructured_Data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUCTRlmqkYej"
   },
   "source": [
    "# environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uqJkFQi8kRLG"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U \"torch==2.1.2\" tensorboard\n",
    "!pip install -q -U \"transformers==4.36.2\" \"datasets==2.16.1\" \"accelerate==0.26.1\" \"bitsandbytes==0.42.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y4oY8OhlSJW",
    "outputId": "e39f553f-a17a-4997-892c-aef0769bbdd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.10/dist-packages (0.23.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.11.0)\n",
      "Requirement already satisfied: InquirerPy==0.3.4 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (0.3.4)\n",
      "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (0.3.4)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.43)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2024.2.2)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bnvOujQvykoL"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4pxc9ezyZXj",
    "outputId": "7ff15e1c-03e8-4e37-b270-4c07e2e2806f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgJQJjD_kIMW",
    "outputId": "88249918-12b9-4e6c-95cc-526ac4ddd509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \"token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FI0LhEgMrokc"
   },
   "source": [
    "# Library Import & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QRwzLnrYcecB"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline,\n",
    "                          logging)\n",
    "from trl import setup_chat_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kKmwJXzteKLv"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHqdleqQy-3R"
   },
   "source": [
    "# Load Dataset & Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iMNxH4bszw68"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7Ioe4TlmDwx",
    "outputId": "ce14496f-38dc-4a26-e488-4788e47edfc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   text               22 non-null     object \n",
      " 1   label              22 non-null     object \n",
      " 2   prediction         22 non-null     object \n",
      " 3   max_prob           22 non-null     float64\n",
      " 4   prob_distribution  22 non-null     object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1008.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# df_miss = pd.read_csv(\"./data/depression_missclassification_cases.csv\")\n",
    "df_miss = pd.read_csv(\"./data/mixed_emotion_set_missclassification_cases.csv\")\n",
    "df_miss.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WHxPV_rVX1ep",
    "outputId": "526b9916-ad05-4e7e-ed5a-0ecff77dbf72"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_miss\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"I am a housewife in my 20s. Through early marriage and childbirth, I have built a happy home and welcomed an irreplaceable, adorable baby. However, at times, I feel despair due to the halt in my career development. While staying at home every day to prepare meals for the children, do laundry, and take care of my husband is certainly worthwhile, there are moments when I also feel the desire to pursue my own career. Sometimes, I feel envious when I see my friends' careers, and I worry that my husband might one day feel useless. While it is joyful to see the baby and participate in their growth process, sometimes watching the baby due to anxiety doesn't feel enjoyable. Sometimes, even when the baby is playful, I can't smile.\",\n          \"As a senior here at Korea University, I wanted to take a moment to share with you the incredible opportunities that await you by getting involved in our student council. Being part of the student council isn't just about holding a title or attending meetings\\u2014it's about making a real difference in our school community.\\nFirst and foremost, joining the student council is an excellent way to develop leadership skills that will serve you well throughout your life. Whether you're organizing events, advocating for student needs, or leading initiatives to improve our school, you'll have countless opportunities to hone your leadership abilities and make a positive impact.\\nBeyond personal development and advocacy, participating in the student council also offers numerous opportunities for personal growth and enrichment. From organizing school events and fundraisers to collaborating with fellow students and faculty members, you'll develop valuable teamwork, communication, and problem-solving skills that are essential for success in any endeavor.\\nAdditionally, being part of the student council opens doors to new friendships and connections that can last a lifetime. You'll have the chance to work closely with a diverse group of students who share your passion for making a difference, forging bonds that extend far beyond the confines of our school walls.\\nFurthermore, serving on the student council provides a sense of pride and fulfillment that comes from contributing to something greater than yourself. Whether you're planning spirit weeks, organizing community service projects, or advocating for positive changes in our school policies, you'll experience the satisfaction of knowing that you're making a meaningful impact on the lives of your fellow students and our school community as a whole.\\nFurthermore, serving on the student council provides a sense of pride and fulfillment that comes from contributing to something greater than yourself. Whether you're planning spirit weeks, organizing community service projects, or advocating for positive changes in our school policies, you'll experience the satisfaction of knowing that you're making a meaningful impact on the lives of your fellow students and our school community as a whole.\\nIn conclusion, I urge you to consider joining the student council and becoming an active participant in shaping the future of our school. The experiences, skills, and relationships you'll gain through this journey are invaluable, and I have no doubt that you'll look back on your time in the student council with fondness and gratitude.\\nIf you have any questions or would like to learn more about getting involved, please don't hesitate to reach out. Together, let's make our school an even better place for everyone.\",\n          \"In the latest entertainment industry news, there's been a buzz surrounding the release of several highly anticipated movies and TV shows. From blockbuster sequels to gripping dramas, audiences are eagerly awaiting new releases from major studios and streaming platforms alike. Additionally, there's been a surge in the popularity of virtual concerts and live streaming events, as performers find innovative ways to connect with fans amid ongoing restrictions on live gatherings. Moreover, the industry has seen a rise in diversity and inclusion efforts, with more representation of marginalized communities both in front of and behind the camera. Overall, the entertainment landscape continues to evolve, offering a diverse array of content to audiences worldwide.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Depression\",\n          \"Neutral\",\n          \"Happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Depression\",\n          \"Happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13864746482817905,\n        \"min\": 0.5762571096420288,\n        \"max\": 0.9942519664764404,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.9039905071258544,\n          0.989175260066986\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_distribution\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"[0.09373518079519272, 0.002274321625009179, 0.9039905071258545]\",\n          \"[0.007150223478674889, 0.0036744659300893545, 0.9891752600669861]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_miss"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1c07290a-5476-4398-8df4-84cb9a4c5243\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>max_prob</th>\n",
       "      <th>prob_distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a housewife in my 20s. Through early marr...</td>\n",
       "      <td>Depression</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.903991</td>\n",
       "      <td>[0.09373518079519272, 0.002274321625009179, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despite my successful career and the admiratio...</td>\n",
       "      <td>Depression</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.576257</td>\n",
       "      <td>[0.41973501443862915, 0.004007911309599876, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mom and Dad had another big fight about who ge...</td>\n",
       "      <td>Depression</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.609991</td>\n",
       "      <td>[0.38730886578559875, 0.0027002866845577955, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite my professional success and recognitio...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.960916</td>\n",
       "      <td>[0.0369863286614418, 0.002097291639074683, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a teenager with a passion for music and dre...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.861305</td>\n",
       "      <td>[0.13400466740131378, 0.004690449219197035, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c07290a-5476-4398-8df4-84cb9a4c5243')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1c07290a-5476-4398-8df4-84cb9a4c5243 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1c07290a-5476-4398-8df4-84cb9a4c5243');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d7fd82b3-932e-4829-b7a7-b8e88c4f314c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7fd82b3-932e-4829-b7a7-b8e88c4f314c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d7fd82b3-932e-4829-b7a7-b8e88c4f314c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text       label prediction  \\\n",
       "0  I am a housewife in my 20s. Through early marr...  Depression      Happy   \n",
       "1  Despite my successful career and the admiratio...  Depression      Happy   \n",
       "2  Mom and Dad had another big fight about who ge...  Depression      Happy   \n",
       "3  Despite my professional success and recognitio...     Neutral      Happy   \n",
       "4  As a teenager with a passion for music and dre...     Neutral      Happy   \n",
       "\n",
       "   max_prob                                  prob_distribution  \n",
       "0  0.903991  [0.09373518079519272, 0.002274321625009179, 0....  \n",
       "1  0.576257  [0.41973501443862915, 0.004007911309599876, 0....  \n",
       "2  0.609991  [0.38730886578559875, 0.0027002866845577955, 0...  \n",
       "3  0.960916  [0.0369863286614418, 0.002097291639074683, 0.9...  \n",
       "4  0.861305  [0.13400466740131378, 0.004690449219197035, 0....  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aiwiJ4dI108D"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = df_miss[\"text\"], df_miss[\"prediction\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hkn7MpMcfI0"
   },
   "source": [
    "# LLM Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "2d59c719a2b34fe6a80364825abf3851",
      "15a42876fac14223b90e188aee3fc7b4",
      "eae9b81a99c947e8b197e7b2760a39b4",
      "fb4855e26bbb419ab7308d67f3c059af",
      "abd45fde2b204b95899bc5179eb9c5b8",
      "d9121356a72c47f785cec2bc1cb986fc",
      "71172668e24442b0a8f1af7ffbddd6ba",
      "8d7de18d5f8e416f80e31ca3adbc1259",
      "198944885d4847f1bf31aa7bccfabd8c",
      "1ec25733046a41d39d6f2a0b291c733c",
      "efbd44b2ad724da198b0c1d7ee77c010"
     ]
    },
    "id": "h1YJaCaykIMd",
    "outputId": "6b97c44f-197a-43c6-be69-c83bc1e8ccee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d59c719a2b34fe6a80364825abf3851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_LLM_huggingface(model_name, device, compute_dtype):\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                                  trust_remote_code=True,\n",
    "                                                  )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=compute_dtype,\n",
    "        device_map=device,\n",
    "        # quantization_config=bnb_config,\n",
    "    )\n",
    "    return [tokenizer, model]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "models = [\"meta-llama/Llama-2-7b-chat-hf\", \"meta-llama/Meta-Llama-3-8B-Instruct\"] # Need login\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "LLaMA2 = load_LLM_huggingface(models[0], device, compute_dtype)\n",
    "LLaMA3 = load_LLM_huggingface(models[1], device, compute_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaRGqHo2N5xa"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ao-bPqH-TFF9"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wK23ueY1Xcxy"
   },
   "outputs": [],
   "source": [
    "def LLaMA3_Chat_completion(model, data, label, requests):\n",
    "    # model[0] == tokenizer / model[1] == model\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": requests[0]},\n",
    "        {\"role\": \"user\", \"content\": requests[1]},\n",
    "    ]\n",
    "\n",
    "    def chatting(role, content):\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def reply():\n",
    "        input_ids = model[0].apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model[1].device)\n",
    "\n",
    "        terminators = [\n",
    "            model[0].eos_token_id,\n",
    "            model[0].convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "        ]\n",
    "\n",
    "        outputs = model[1].generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=model[0].eos_token_id\n",
    "        )\n",
    "        response = outputs[0][input_ids.shape[-1]:]\n",
    "        return model[0].decode(response, skip_special_tokens=True)\n",
    "    # first step\n",
    "    chatting(\"assistant\", reply())\n",
    "    chatting(\"user\", requests[-1](data, label))\n",
    "    chatting(\"assistant\", reply())\n",
    "\n",
    "    for question in requests[2:-1]:\n",
    "        chatting(\"user\", question)\n",
    "        chatting(\"assistant\", reply())\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZNMynfLiasq"
   },
   "outputs": [],
   "source": [
    "def LLaMA3_parser(messages):\n",
    "    result = []\n",
    "    for message in messages[5:]:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            result.append(message[\"content\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xPArzhhZUgX"
   },
   "outputs": [],
   "source": [
    "question_func = lambda text, label: f\"Text: {text}\\n\\nAI_Predicted_label: {label}\"\n",
    "version_request = [# Version1 [Yes or no / object / percentatge]\n",
    "                [\"You are a psychologist.\", # system role\n",
    "                \"\"\"We'll send you the text data and the label classified by the corresponding AI analysis. The data is a mix of one or more of the three emotions: 'Depression', 'Neutral', and 'Happy'.\n",
    "                Using this data and the labels, please answer my questions\"\"\",\n",
    "                \"Is the label analyzed by AI right? Please answer as concisely as possible.\",\n",
    "                \"I see, please even make an objective analysis of that.\",\n",
    "                \"\"\"Finally, please provide the percentages of emotions in the aforementioned data in the order of 'depressed', 'neutral', and 'happy'. No other explanation is needed, just the percentages separated by commas.\"\"\",\n",
    "                question_func],\n",
    "                # Version2 [object / Y or N / percentage]\n",
    "                [\"You are a psychologist.\", # system role\n",
    "                \"\"\"We'll send you the text data and the label classified by the corresponding AI analysis. The data is a mix of one or more of the three emotions: 'Depression', 'Neutral', and 'Happy'.\n",
    "                Using this data and the labels, please answer my questions\"\"\",\n",
    "                \"Perform an objective analysis of that data\"\n",
    "                \"Does your analysis match the labels predicted by the AI?\",\n",
    "                \"\"\"Finally, please provide the percentages of emotions in the aforementioned data in the order of 'depressed', 'neutral', and 'happy'. No other explanation is needed, just the percentages separated by commas.\"\"\",\n",
    "                question_func],\n",
    "                # Version3 [object / Y or N / percentage] + Role Change and help me analyse\n",
    "                [\"You're a psychotherapist. Help me analyze\", # system role\n",
    "                \"\"\"We'll send you the text data and the label classified by the corresponding AI analysis. The data is a mix of one or more of the three emotions: 'Depression', 'Neutral', and 'Happy'.\n",
    "                Using this data and the labels, please answer my questions\"\"\",\n",
    "                \"Perform an objective analysis of that data\"\n",
    "                \"Does your analysis match the labels predicted by the AI?\",\n",
    "                \"\"\"Finally, please provide the percentages of emotions in the aforementioned data in the order of 'depressed', 'neutral', and 'happy'. No other explanation is needed, just the percentages separated by commas.\"\"\",\n",
    "                question_func]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "C2u-rFIJo4Ld"
   },
   "outputs": [],
   "source": [
    "# Version running\n",
    "for version in range(1,4):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    requests = version_request[version-1]\n",
    "    for X, y in tqdm(zip(X_train.values, y_train), desc = \"Generate Reasoning\"):\n",
    "        a.append(LLaMA3_parser(LLaMA3_Chat_completion(LLaMA2, X, y, requests)))\n",
    "        b.append(LLaMA3_parser(LLaMA3_Chat_completion(LLaMA3, X, y, requests)))\n",
    "    answers1 = []\n",
    "    answers2 = []\n",
    "    answers3 = []\n",
    "    for item in a:\n",
    "        answers1.append(\"-\")\n",
    "        answers2.append(\"-\")\n",
    "        answers3.append(\"-\")\n",
    "        answers1.append(item[0])\n",
    "        answers2.append(item[1])\n",
    "        answers3.append(item[2])\n",
    "    answers4 = []\n",
    "    answers5 = []\n",
    "    answers6 = []\n",
    "    for item in b:\n",
    "        answers4.append(item[0])\n",
    "        answers5.append(item[1])\n",
    "        answers6.append(item[2])\n",
    "    df1 = pd.concat([X_train.reset_index(drop=True), df_miss[[\"label\", \"prediction\"]]], axis = 1)\n",
    "    df2 = pd.DataFrame({\"LLaMA2_1\": answers1, \"LLaMA2_2\": answers2, \"LLaMA2_3\": answers3,\n",
    "                        \"LLaMA3_1\": answers4, \"LLaMA3_2\": answers5, \"LLaMA3_3\": answers6})\n",
    "    df = pd.concat([df1, df2], axis = 1)\n",
    "    df.to_csv(f\"./data/log/result_ver3_0524_mixed_miscalssification_ver{version}_real.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15a42876fac14223b90e188aee3fc7b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9121356a72c47f785cec2bc1cb986fc",
      "placeholder": "​",
      "style": "IPY_MODEL_71172668e24442b0a8f1af7ffbddd6ba",
      "value": "Loading checkpoint shards:  50%"
     }
    },
    "198944885d4847f1bf31aa7bccfabd8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ec25733046a41d39d6f2a0b291c733c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d59c719a2b34fe6a80364825abf3851": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15a42876fac14223b90e188aee3fc7b4",
       "IPY_MODEL_eae9b81a99c947e8b197e7b2760a39b4",
       "IPY_MODEL_fb4855e26bbb419ab7308d67f3c059af"
      ],
      "layout": "IPY_MODEL_abd45fde2b204b95899bc5179eb9c5b8"
     }
    },
    "71172668e24442b0a8f1af7ffbddd6ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d7de18d5f8e416f80e31ca3adbc1259": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abd45fde2b204b95899bc5179eb9c5b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9121356a72c47f785cec2bc1cb986fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eae9b81a99c947e8b197e7b2760a39b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d7de18d5f8e416f80e31ca3adbc1259",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_198944885d4847f1bf31aa7bccfabd8c",
      "value": 2
     }
    },
    "efbd44b2ad724da198b0c1d7ee77c010": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb4855e26bbb419ab7308d67f3c059af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ec25733046a41d39d6f2a0b291c733c",
      "placeholder": "​",
      "style": "IPY_MODEL_efbd44b2ad724da198b0c1d7ee77c010",
      "value": " 2/4 [00:44&lt;00:44, 22.09s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
